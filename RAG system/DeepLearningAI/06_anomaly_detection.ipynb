{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqNY0ljqY+LLSTVgZDDpig"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import the Needed Packages"],"metadata":{"id":"xEIzRiZJFmT2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4fGzW_-kPjv"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from pinecone import Pinecone, ServerlessSpec\n","from sentence_transformers import SentenceTransformer, InputExample, losses, models, util\n","from torch.utils.data import DataLoader\n","from torch import nn\n","from tqdm.auto import tqdm\n","from DLAIUtils import Utils\n","import torch\n","import time\n","import torch\n","import os"],"metadata":{"id":"uAukz9FZElXV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Setup Pinecone"],"metadata":{"id":"iBwFnnFAG8Q2"}},{"cell_type":"code","source":["utils = Utils()\n","PINECONE_API_KEY = utils.get_pinecone_api_key()"],"metadata":{"id":"nHMHR42qElaD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n","\n","pinecone = Pinecone(api_key=PINECONE_API_KEY)\n","\n","if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n","  pinecone.delete_index(INDEX_NAME)\n","pinecone.create_index(name=INDEX_NAME, dimension=256, metric='cosine',\n","  spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n","index = pinecone.Index(INDEX_NAME)"],"metadata":{"id":"tcI9d6ONElc7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the Dataset"],"metadata":{"id":"IESm6dnTFjIe"}},{"cell_type":"code","source":["!head -5 sample.log"],"metadata":{"id":"2DfUmDftElfJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head -5 training.txt"],"metadata":{"id":"X7jFlZmmElhn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check cuda and Setup the Model"],"metadata":{"id":"0Nzt4E8PFgNX"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","#set maximum number of tokens that BERT will process in a single sequence.\n","word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=768)\n","\n","#Adds a pooling layer after the word embedding model.\n","#This layer aggregates the word embeddings into a single sentence embedding. It typically computes features like mean and max pooling.\n","pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n","\n","#Adds a dense (fully connected) layer to the model.\n","dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(), out_features=256, activation_function=nn.Tanh())\n","\n","#Combines the word embedding, pooling, and dense layers into a single Sentence Transformer model.\n","model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model], device=device)\n","device"],"metadata":{"id":"QDMiwmYjElkT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train the Model"],"metadata":{"id":"L8wew98aFcyA"}},{"cell_type":"code","source":["train_examples = []\n","with open('./training.txt', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        line = line.strip()\n","        if line:\n","            #sample,sample and relationship between them\n","            a, b, label = line.split('^')\n","            train_examples.append(InputExample(texts=[a, b], label=float(label)))\n","\n","#Define dataset, the dataloader and the training loss\n","\n","#used in training to gradually ramp up the learning rate, which can help improve model performance.\n","warmup_steps=100\n","\n","train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n","\n","#computes the cosine similarity between the embeddings of the texts in each InputExample.\n","train_loss = losses.CosineSimilarityLoss(model)"],"metadata":{"id":"9fV9jRESElmx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pickle\n","load_pretrained_model = True\n","if load_pretrained_model:\n","    #binary read mode\n","    trained_model_file = open('./data/pretrained_model', 'rb')\n","    #deserialize the model object from the file.\n","    db = pickle.load(trained_model_file)\n","    trained_model_file.close()\n","else:\n","    #Training a New Model (if not loading a pre-trained one):\n","    model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=16, warmup_steps=100)\n","\n","samples = []\n","with open('sample.log', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        line = line.strip()\n","        if line: # only the raw line is added to the samples list now.\n","            #emb = model.encode([line])\n","            samples.append(line)"],"metadata":{"id":"xy3yfCvdElpd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create Embeddings and Upsert to Pinecone"],"metadata":{"id":"d2AF9FsrNIzt"}},{"cell_type":"code","source":["emb = model.encode(samples)"],"metadata":{"id":"gjicO7e9Elsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prepped = []\n","for i in tqdm(range(len(samples))):\n","  v = {'id':f'{i}', 'values':emb[i].tolist(), 'metadata':{'log':samples[i]}}\n","  prepped.append(v)\n","index.upsert(prepped)"],"metadata":{"id":"VekM7Z5SNNP1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Find the Anomaly"],"metadata":{"id":"YhifOYHnO_Bt"}},{"cell_type":"code","source":["good_log_line = samples[0]\n","print(good_log_line)\n","results = []\n","while len(results)==0:  # After the upserts, it might take a few seconds for index to be ready for query.\n","    time.sleep(2)       # If results is empty we try again two seconds later.\n","    queried = index.query(\n","        vector=emb[0].tolist(),\n","        include_metadata=True,\n","        top_k=100\n","    )\n","    results = queried['matches']\n","    print(\".:. \",end=\"\")\n","\n","#Iterates through the top 10 results and prints their similarity scores and the corresponding log lines.\n","for i in range(0,10) :\n","  print(f\"{round(results[i]['score'], 4)}\\t{results[i]['metadata']['log']}\")\n","last_element = len(results) -1\n","#Also prints score of the  last element in the results with the log line\n","print(f\"{round(results[last_element]['score'], 4)}\\t{results[last_element]['metadata']['log']}\")"],"metadata":{"id":"MqUzojBUPBVQ"},"execution_count":null,"outputs":[]}]}