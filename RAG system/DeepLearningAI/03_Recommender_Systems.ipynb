{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAp0DykabIHChR7o7m4ZK0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"L5ieT2Y-Dgdb"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from openai import OpenAI\n","from pinecone import Pinecone, ServerlessSpec\n","from tqdm.auto import tqdm, trange\n","from DLAIUtils import Utils\n","\n","import pandas as pd\n","import time\n","import os\n"]},{"cell_type":"code","source":["utils = Utils()\n","PINECONE_API_KEY = utils.get_pinecone_api_key()\n","OPENAI_API_KEY = utils.get_openai_api_key()\n"],"metadata":{"id":"FwYn7PSBDrzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget -q --show-progress -O all-the-news-3.zip \"https://www.dropbox.com/scl/fi/wruzj2bwyg743d0jzd7ku/all-the-news-3.zip?rlkey=rgwtwpeznbdadpv3f01sznwxa&dl=1\"\n","\n","!unzip all-the-news-3.zip\n"],"metadata":{"id":"2rWc5DeEDr4e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('./data/all-the-news-3.csv', 'r') as f:\n","    #Reads the first line, which typically contains the header (column names) of the CSV file.\n","    header = f.readline()\n","    print(header)\n",""],"metadata":{"id":"rvAPO5AkDr6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('./data/all-the-news-3.csv', nrows=99)\n","#displays the first five rows of the DataFrame for initial inspection of the data.\n","df.head()\n"],"metadata":{"id":"ERMXmzI8Dr88"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Setup Pinecone\n","openai_client = OpenAI(api_key=OPENAI_API_KEY)\n","util = Utils()\n","INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n","pinecone = Pinecone(api_key=PINECONE_API_KEY)\n","\n","if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n","  pinecone.delete_index(INDEX_NAME)\n","\n","pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',\n","  spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n","\n","index = pinecone.Index(INDEX_NAME)\n"],"metadata":{"id":"9dIXxi_XFdRl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#creating embeddings of news titles and indexing them in Pinecone, so you can later query the index to find semantically similar articles\n","\n","#Create Embeddings of the News Titles\n","def get_embeddings(articles, model=\"text-embedding-ada-002\"):\n","   return openai_client.embeddings.create(input = articles, model=model)\n","\n","CHUNK_SIZE=400\n","TOTAL_ROWS=10000\n","\n","#Initializes a progress bar using tqdm for visual feedback on the processing progress.\n","progress_bar = tqdm(total=TOTAL_ROWS)\n","\n","#Reading the Dataset in Chunks\n","chunks = pd.read_csv('./data/all-the-news-3.csv', chunksize=CHUNK_SIZE,\n","                     nrows=TOTAL_ROWS)\n","chunk_num = 0\n","for chunk in chunks:\n","\n","    #get title, do embedding for it\n","    titles = chunk['title'].tolist()\n","    embeddings = get_embeddings(titles)\n","\n","    #build a list of id,embedding and metadata\n","    prepped = [{'id':str(chunk_num*CHUNK_SIZE+i), 'values':embeddings.data[i].embedding,\n","                'metadata':{'title':titles[i]},} for i in range(0,len(titles))]\n","\n","    chunk_num = chunk_num + 1\n","    if len(prepped) >= 200:\n","      index.upsert(prepped)\n","      prepped = []\n","\n","    #Updates the progress bar based on the number of rows processed in the current chunk\n","    progress_bar.update(len(chunk))\n","\n","index.describe_index_stats()"],"metadata":{"id":"rh0m8mPVFg3b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Build the Recommender System\n","def get_recommendations(pinecone_index, search_term, top_k=10):\n","  #generates an embedding for the search term\n","  embed = get_embeddings([search_term]).data[0].embedding\n","  #queries the Pinecone index with this embedding\n","  res = pinecone_index.query(vector=embed, top_k=top_k, include_metadata=True)\n","  return res\n","\n","#Getting Recommendations for a Search Term\n","reco = get_recommendations(index, 'obama')\n","\n","#Printing the Recommendations\n","for r in reco.matches:\n","    #similarity score (r.score) and the title of the article (r.metadata[\"title\"])\n","    print(f'{r.score} : {r.metadata[\"title\"]}')\n",""],"metadata":{"id":"X0f0shSkJ-IS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create Embeddings of 'All' News Content\n","\n","#check existence, typically done to start fresh with a new dataset or schema.\n","if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n","  pinecone.delete_index(name=INDEX_NAME)\n","\n","pinecone.create_index(name=INDEX_NAME, dimension=1536, metric='cosine',\n","  spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n","articles_index = pinecone.Index(INDEX_NAME)\n","\n","def embed(embeddings, title, prepped, embed_num):\n","    for embedding in embeddings.data:\n","        prepped.append({'id':str(embed_num), 'values':embedding.embedding, 'metadata':{'title':title}})\n","        embed_num += 1\n","        if len(prepped) >= 100:\n","            articles_index.upsert(prepped)\n","            prepped.clear()\n","    return embed_num\n"],"metadata":{"id":"M9gCXtsoJ-cg","executionInfo":{"status":"ok","timestamp":1707084845829,"user_tz":360,"elapsed":577,"user":{"displayName":"Tianzong Zhang","userId":"18141008230024928237"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#processes news articles, splits them into chunks, generates embeddings for each chunk, and then upserts them into the Pinecone index.\n","\n","\n","#news_data_rows_num sets the number of news articles to process.\n","news_data_rows_num = 100\n","\n","#embed_num will be used to track the ID for each embedding.\n","embed_num = 0\n","\n","#text_splitter is an instance of RecursiveCharacterTextSplitter for splitting articles into chunks with a specified size and overlap.\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n","\n","#prepped is a list to accumulate data for batch upserts.\n","prepped = []\n","\n","df = pd.read_csv('./data/all-the-news-3.csv', nrows=news_data_rows_num)\n","articles_list = df['article'].tolist()\n","titles_list = df['title'].tolist()\n","\n","\n","for i in range(0, len(articles_list)):\n","    print(\".\",end=\"\")\n","    art = articles_list[i]\n","    title = titles_list[i]\n","    if art is not None and isinstance(art, str):\n","      texts = text_splitter.split_text(art)\n","      embeddings = get_embeddings(texts)\n","      embed_num = embed(embeddings, title, prepped, embed_num)"],"metadata":{"id":"0nUVG3oaJ-sE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["articles_index.describe_index_stats()"],"metadata":{"id":"wfmsDaFoNbed"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reco = get_recommendations(articles_index, 'obama', top_k=100)\n","seen = {}\n","for r in reco.matches:\n","    title = r.metadata['title']\n","\n","    #ensures that each recommended article is only printed once, even if it appears multiple times in the recommendation results,\n","    # which is useful in cases where multiple chunks of the same article might be similar to the search query.\n","    if title not in seen:\n","        print(f'{r.score} : {title}')\n","        seen[title] = '.'"],"metadata":{"id":"8ozXGEcLQB1I"},"execution_count":null,"outputs":[]}]}