{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0bqy17yBwenm6XVHgymVn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oEbzuxA4pBxd"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["from deepface import DeepFace\n","from pinecone import Pinecone, ServerlessSpec\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from tqdm import tqdm\n","from DLAIUtils import Utils\n","\n","\n","import contextlib\n","import glob\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import time"],"metadata":{"id":"dnXC6K7eqdXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get api key\n","utils = Utils()\n","PINECONE_API_KEY = utils.get_pinecone_api_key()"],"metadata":{"id":"WvxU6YYWqdaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#f - file path\n","def show_img(f):\n","  img = plt.imread(f)\n","  #(4,3) inches\n","  plt.figure(figsize=(4,3))\n","  plt.imshow(img)\n","\n","show_img('family/dad/P06260_face5.jpg')"],"metadata":{"id":"M4_rgD9yqddX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Setup Pinecone\n","MODEL = \"Facenet\"\n","INDEX_NAME = utils.create_dlai_index_name('dl-ai')\n","\n","pinecone = Pinecone(api_key=PINECONE_API_KEY)"],"metadata":{"id":"wVhiqeeOqdf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Create Embeddings Using DeepFace\n","def generate_vectors():\n","  #Defines the path to the output file where the embeddings will be stored\n","  VECTOR_FILE = \"./vectors.vec\"\n","\n","  #remove the file if it exists (to start fresh), and ignores any FileNotFoundError using contextlib.suppress.\n","  with contextlib.suppress(FileNotFoundError):\n","    os.remove(VECTOR_FILE)\n","\n","  with open(VECTOR_FILE, \"w\") as f:\n","    for person in [\"mom\", \"dad\", \"child\"]:\n","      #all files in each category's directory\n","      files = glob.glob(f'family/{person}/*')\n","      for file in tqdm(files):\n","        try:\n","          #generates an embedding using DeepFace.represent\n","          #'enforce_detection=False' allows processing without mandatory face detection (useful in cases where face detection might fail).\n","          #[0]:Since facial recognition models can detect multiple faces in a single image, this list could potentially contain several embeddings.\n","          #['embedding'] from the returned dictionary\n","          embedding = DeepFace.represent(img_path=file, model_name=MODEL, enforce_detection=False)[0]['embedding']\n","          #Uses os.path.basename(file) to get just the filename without the path.\n","          f.write(f'{person}:{os.path.basename(file)}:{embedding}\\n')\n","        except (ValueError, UnboundLocalError, AttributeError) as e:\n","          print(e)\n","\n","generate_vectors()"],"metadata":{"id":"eejUlrL7qdie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#a shell command to display the first 10 lines of the generated file, showing a preview of the embeddings.\n","!head -10 vectors.vec"],"metadata":{"id":"K-aLXHQ0qdlD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plot the Data of Images\n","def gen_tsne_df(person, perplexity):\n","\n","    vectors =[]\n","    with open('./vectors.vec', 'r') as f:\n","      for line in tqdm(f):\n","        p, orig_img, v = line.split(':')\n","        if person == p:\n","            # the embedding vector (v) is evaluated from a string to a list of numbers using eval()\n","            vectors.append(eval(v))\n","\n","    #Initializes PCA (Principal Component Analysis) to reduce the dimensionality of the vectors to 8 dimensions.\n","    #This step is often done before t-SNE to make the computation more efficient and to reduce noise.\n","    pca = PCA(n_components=8)\n","\n","    #Initializes the t-SNE algorithm, specifying 2 output dimensions\n","    tsne = TSNE(2, perplexity=perplexity, random_state = 0, n_iter=1000,\n","        verbose=0, metric='euclidean', learning_rate=75)\n","    print(f'transform {len(vectors)} vectors')\n","\n","    #Transforms the vectors using PCA.\n","    pca_transform = pca.fit_transform(vectors)\n","\n","    #Transforms the PCA-reduced vectors into a 2-dimensional space.\n","    embeddings2d = tsne.fit_transform(pca_transform)\n","\n","    #Constructs a Pandas DataFrame from the 2D embeddings, with columns x and y representing the two dimensions.\n","    return pd.DataFrame({'x':embeddings2d[:,0], 'y':embeddings2d[:,1]})\n","\n","def plot_tsne(perplexity, model):\n","\n","    #Initializes a Matplotlib subplot with a specified figure size.\n","    #Sets up the grid and customizes the color and style of the plot's spines (borders).\n","    (_, ax) = plt.subplots(figsize=(8,5))\n","    #plt.style.use('seaborn-whitegrid')\n","    plt.grid(color='#EAEAEB', linewidth=0.5)\n","    ax.spines['top'].set_color(None)\n","    ax.spines['right'].set_color(None)\n","    ax.spines['left'].set_color('#2B2F30')\n","    ax.spines['bottom'].set_color('#2B2F30')\n","\n","    #\n","    colormap = {'dad':'#ee8933', 'child':'#4fad5b', 'mom':'#4c93db'}\n","\n","    #Plotting Embeddings for Each Person\n","    for person in colormap:\n","        embeddingsdf = gen_tsne_df(person, perplexity)\n","        #Plots these embeddings on the scatter plot using the scatter method.\n","        ax.scatter(embeddingsdf.x, embeddingsdf.y, alpha=.5,\n","                   label=person, color=colormap[person])\n","\n","    #Adding Titles and Legend\n","    plt.title(f'Scatter plot of faces using {model}', fontsize=16, fontweight='bold', pad=20)\n","    plt.suptitle(f't-SNE [perplexity={perplexity}]', y=0.92, fontsize=13)\n","    plt.legend(loc='best', frameon=True)\n","    plt.show()"],"metadata":{"id":"SejNMjaJqdnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_tsne(44, 'facenet')"],"metadata":{"id":"I7mhTXwFqdqP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Store the Embeddings in Pinecone\n","if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n","  pinecone.delete_index(INDEX_NAME)\n","pinecone.create_index(name=INDEX_NAME, dimension=128, metric='cosine',\n","  spec=ServerlessSpec(cloud='aws', region='us-west-2'))\n","\n","index = pinecone.Index(INDEX_NAME)\n","\n","def store_vectors():\n","  with open(\"vectors.vec\", \"r\") as f:\n","    for line in tqdm(f):\n","        person, file, vec = line.split(':')\n","\n","        #Uses index.upsert to insert or update the vector in the Pinecone index.\n","        #Each vector is given a unique ID (f'{person}-{file}') and is accompanied by metadata ({\"person\":person, \"file\":file}).\n","        index.upsert([(f'{person}-{file}', eval(vec), {\"person\":person, \"file\":file})])\n","\n","store_vectors()\n","\n","index.describe_index_stats()"],"metadata":{"id":"B4U9bOG8qdtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculate the Similarity Scores\n","#This function can be used to assess the similarity between two sets of facial embeddings, like comparing a parent's facial features with those of a child.\n","#It's a way to quantitatively measure the facial resemblance between two individuals based on the embeddings generated by a facial recognition model.\n","\n","\n","#parent: The identifier (key in vec_groups) for the first group of embeddings to be queried.\n","#child: The identifier for the second group of embeddings, which will be used as a filter in the query.\n","def test(vec_groups, parent, child):\n","  #Initializes the Pinecone index for querying.\n","  index = pinecone.Index(INDEX_NAME)\n","  #Retrieves the embeddings for the parent.\n","  parent_vecs = vec_groups[parent]\n","\n","  #the number of top results to retrieve for each query to the Pinecone index.\n","  K = 10\n","\n","  #In this case, SAMPLE_SIZE being 10 means you perform 10 separate queries to the index, each with a different embedding from the parent group.\n","  #This parameter allows you to average the similarity scores across multiple queries, giving a more holistic measure of similarity between two groups (like \"parent\" and \"child\").\n","  SAMPLE_SIZE = 10\n","  sum = 0\n","\n","  #Querying and Accumulating Scores\n","  for i in tqdm(range(0,SAMPLE_SIZE)):\n","    query_response = index.query(\n","      top_k=K,\n","      vector = parent_vecs[i],\n","      filter={\n","        \"person\": {\"$eq\": child}\n","      }\n","    )\n","    for row in query_response[\"matches\"]:\n","      sum  = sum + row[\"score\"]\n","  print(f'\\n\\n{parent} AVG: {sum / (SAMPLE_SIZE*K)}')"],"metadata":{"id":"UdCzQTWGqdv2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_scores():\n","  index = pinecone.Index(INDEX_NAME)\n","  vec_groups = {\"dad\":[], \"mom\":[], \"child\":[]}\n","  with open(\"vectors.vec\", \"r\") as f:\n","    for line in tqdm(f):\n","      person, file, vec = line.split(':')\n","      vec_groups[person].append(eval(vec))\n","  print(f\"DAD {'-' * 20}\")\n","  test(vec_groups, \"dad\", \"child\")\n","  print(f\"MOM {'-' * 20}\")\n","  test(vec_groups, \"mom\", \"child\")\n","\n","compute_scores()"],"metadata":{"id":"suoVsA1Zqdyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Check the Matching Images\n","child_base = 'family/child/P06310_face1.jpg'\n","show_img(child_base)"],"metadata":{"id":"LkYJMhZs5H3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1uDrwMJQ5IIo"},"execution_count":null,"outputs":[]}]}